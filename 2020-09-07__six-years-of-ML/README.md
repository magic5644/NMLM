# Six ans du NMLM et ce qui s'est passé

Septembre marquera le début de la septième année du NMLM. Nous avons
évoqué, Hugo, Stefan, et moi, de le fêter avec un review des points
les plus forts du ML depuis six ans. L'idée est de faire une suite de
quickies (15 minutes chaque) au niveau de quelqu'un qui est expert en
ML mais qui a bizarrement loupé juste ce sujet-là. Donc, expliquer ce
que c'est, pourquoi ça mérite d'être considéré comme un point fort et
essentiel du ML depuis 2014, et comment marche la théorie.

Le programme de la soirée :

1. Introduction : 6 ans NMLM [Jeff Abrahamson]
2. Computer Vision : ImageNet et l’arrivée du Deep Learning, apprentissage de features, pourquoi les réseaux de neurones profondes marchent mieux [Kelvin Moutet]
3. Natural Language Processing : word embeddings, word2vec, sequence2sequence, attention, transformers (Bert, GPT, Blender, …) [Jeff Abrahamson]
4. Adversarial Learning : GAN, Deep fakes, how to detect deep fakes [Jean-Baptiste Even]
5. Deep Reasoning : Memory Networks, Neural Turing Machines et similaires, learning to program [Hugo Mougard]
6. Jeux et Deep Reinforcement Learning : de AlphaGo à MuZero, de Atari à Dota-2 [Stefan Knerr]

Le MeetUp sera uniquement on-line.
